{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download file from MTA\n",
    "#Input into a PD Dataframe (e.g. correctly label columns)\n",
    "#Helper tables: Define MTA station Mapping\n",
    "#reformat PD into a usable DF - Unit ID, Date-time, station name, entries, exits\n",
    "#sort on unit-id (will sort by time too). remove duplicates. [possibly find a better method]\n",
    "\n",
    "#- Which station has the most number of units? ... Penn Station (unique turnstile units for the Week of Feb 2nd)\n",
    "#- What is the total number of entries & exits across the subway system for February 1, 2013? ...neet to calculate net entries and exits [2hrs]\n",
    "#- Letâ€™s define the busy-ness as sum of entry & exit count. What station was the busiest on February 1, 2013? What turnstile was the busiest on that date? ... add busyness column. filter for only feb 1. group by station [30 mins]\n",
    "#- What stations have seen the most usage growth/decline in 2013? [NEEDS clarification - since daily variance is significant] ...need to download whole dataset for 2012 and 2013. (speed up calculation)...sum up net transactions for the year [3hrs]\n",
    "#- What dates are the least busy? Could you identify days on which stations were not operating at full capacity or closed entirely? ... [2hrs]\n",
    "#- Bonus:  What hour is the busiest for station CANAL ST in Q1 2013?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#add station name & count number of turnstiles per station\n",
    "def addStationName(filename, raw_MTA_data_tmp):\n",
    "    if 'Station' not in raw_MTA_data_tmp.columns:\n",
    "        remote_station_mapping = pd.read_excel(filename)\n",
    "        remote_station_mapping = remote_station_mapping.drop_duplicates(subset=[\"Remote\"]) #assumption only keep the first occuring station name (e.g. 59th st vs. Lexington ave)\n",
    "        remote_station_mapping[\"UNIT\"] = remote_station_mapping[\"Remote\"]\n",
    "\n",
    "        raw_MTA_data_tmp = raw_MTA_data_tmp.merge(remote_station_mapping[[\"UNIT\", \"Station\"]], on=[\"UNIT\"])\n",
    "    return raw_MTA_data_tmp\n",
    "\n",
    "def addTimeStamp(vec):\n",
    "    x = str(vec[0])\n",
    "    y = str(vec[1])\n",
    "    try:\n",
    "        return datetime.strptime(x + \" \" + y, \"%m-%d-%y %H:%M:%S\" ).strftime(\"%y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        return \"NULL\"\n",
    "\n",
    "def read_MTA_csv(filename):\n",
    "    raw_MTA_data = pd.read_csv(filename,error_bad_lines=False)\n",
    "    raw_MTA_data.columns= [\"C/A\",\"UNIT\",\"SCP\",\"DATE1\",\"TIME1\",\"DESC1\",\"ENTRIES1\",\"EXITS1\",\"DATE2\",\"TIME2\",\"DESC2\",\"ENTRIES2\",\"EXITS2\",\"DATE3\",\n",
    "    \"TIME3\",\"DESC3\",\"ENTRIES3\",\"EXITS3\",\"DATE4\",\"TIME4\",\"DESC4\",\"ENTRIES4\",\"EXITS4\",\"DATE5\",\"TIME5\",\"DESC5\",\"ENTRIES5\",\"EXITS5\",\"DATE6\",\n",
    "    \"TIME6\",\"DESC6\",\"ENTRIES6\",\"EXITS6\",\"DATE7\",\"TIME7\",\"DESC7\",\"ENTRIES7\",\"EXITS7\",\"DATE8\",\"TIME8\",\"DESC8\",\"ENTRIES8\",\"EXITS8\"]\n",
    "    #print(raw_MTA_data.head())\n",
    "\n",
    "    #Loop through raw dataset. for each row, make an entry in the MTA turnstile data set.\n",
    "    raw_MTA_data_tmp = raw_MTA_data.copy(deep=True)\n",
    "    raw_MTA_data_tmp[\"Unit_ID\"] = raw_MTA_data_tmp[\"C/A\"] + raw_MTA_data_tmp[\"UNIT\"] + raw_MTA_data_tmp[\"SCP\"]\n",
    "    raw_MTA_data_tmp = raw_MTA_data_tmp.drop([\"C/A\", \"SCP\"],axis=1)\n",
    "\n",
    "    for i in range(1,8+1):\n",
    "        raw_MTA_data_tmp[\"Datetime_\" + str(i)] = raw_MTA_data_tmp[[\"DATE\" + str(i), \"TIME\" + str(i)]].apply(addTimeStamp,axis=1)\n",
    "\n",
    "    #raw_MTA_data_tmp[\"Date_time_1\"] = raw_MTA_data_tmp.apply(lambda x: datetime.strptime(x[\"DATE1\"] + \" \" + x[\"TIME1\"], \"%m-%d-%y %H:%M:%S\" ).strftime(\"%y-%m-%d %H:%M:%S\"),axis=1) \n",
    "    raw_MTA_data_tmp = raw_MTA_data_tmp.drop([\"DATE1\", \"TIME1\", \"DATE2\", \"TIME2\", \"DATE3\", \"TIME3\", \"DATE4\", \"TIME4\", \"DATE5\", \"TIME5\", \"DATE6\", \"TIME6\", \"DATE7\", \"TIME7\", \"DATE8\", \"TIME8\"],axis=1)\n",
    "    #print(raw_MTA_data_tmp.head())\n",
    "    return raw_MTA_data_tmp\n",
    "\n",
    "raw_MTA_data_tmp = read_MTA_csv(\"~/Projects/NYC_MTA_DATA_ANALYSIS/data/turnstile_130202.txt\")\n",
    "raw_MTA_data_tmp = addStationName(\"../data/Remote-Booth-Station.xls\", raw_MTA_data_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: 'Which station has the most number of units?'\n",
      "count    100\n",
      "Name: 34 ST-PENN STA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1: 'Which station has the most number of units?'\")\n",
    "\n",
    "MTA_turnstiles_unique = raw_MTA_data_tmp.drop_duplicates(subset=[\"Unit_ID\"]).copy(deep=True)\n",
    "stationWithMostTerminals = MTA_turnstiles_unique.groupby(by=\"Station\").agg([\"count\"])[\"UNIT\"].sort_values(by=\"count\",).iloc[-1,:]\n",
    "\n",
    "print(stationWithMostTerminals)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Station               Unit           Datetime  \\\n",
      "0              59 ST   A002R05102-00-00  13-01-27 11:00:00   \n",
      "1              59 ST   A002R05102-00-00  13-01-28 19:00:00   \n",
      "2              59 ST   A002R05102-00-00  13-01-30 03:00:00   \n",
      "3              59 ST   A002R05102-00-00  13-01-31 11:00:00   \n",
      "4              59 ST   A002R05102-00-00  13-02-01 15:00:00   \n",
      "...              ...                ...                ...   \n",
      "30856  RIT-ROOSEVELT  TRAM2R46900-05-01  13-01-29 20:00:00   \n",
      "30857  RIT-ROOSEVELT  TRAM2R46900-05-01  13-01-30 07:48:11   \n",
      "30858  RIT-ROOSEVELT  TRAM2R46900-05-01  13-01-31 08:00:00   \n",
      "30859  RIT-ROOSEVELT  TRAM2R46900-05-01  13-02-01 16:00:00   \n",
      "30860  RIT-ROOSEVELT  TRAM2R46900-05-01               NULL   \n",
      "\n",
      "       Cumulative entries  Cumulative exits     Desc  \n",
      "0               3967826.0         1367578.0  REGULAR  \n",
      "1               3969685.0         1368236.0  REGULAR  \n",
      "2               3971424.0         1368820.0  REGULAR  \n",
      "3               3973086.0         1369749.0  REGULAR  \n",
      "4               3974913.0         1370326.0  REGULAR  \n",
      "...                   ...               ...      ...  \n",
      "30856              5554.0              99.0  REGULAR  \n",
      "30857              5554.0             100.0  REGULAR  \n",
      "30858              5554.0             100.0  REGULAR  \n",
      "30859              5554.0             100.0  REGULAR  \n",
      "30860                 NaN               NaN      NaN  \n",
      "\n",
      "[246888 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert dataframe so that each row has only 1 4-hour block of data\n",
    "\n",
    "def expandRows(raw_MTA_data_tmp):\n",
    "    raw_MTA_data_tmp_x8 = pd.DataFrame()\n",
    "    for i in range(1,8+1):\n",
    "        raw_MTA_data_tmp_copy = raw_MTA_data_tmp.copy(deep=True)\n",
    "        raw_MTA_data_tmp_copy[\"Unit\"] = raw_MTA_data_tmp_copy[\"Unit_ID\"]\n",
    "        raw_MTA_data_tmp_copy[\"Datetime\"] = raw_MTA_data_tmp_copy[\"Datetime_\" + str(i)]\n",
    "        raw_MTA_data_tmp_copy[\"Station\"] = raw_MTA_data_tmp_copy[\"Station\"]\n",
    "        raw_MTA_data_tmp_copy[\"Cumulative entries\"] = raw_MTA_data_tmp_copy[\"ENTRIES\" + str(i)]\n",
    "        raw_MTA_data_tmp_copy[\"Cumulative exits\"] = raw_MTA_data_tmp_copy[\"EXITS\" + str(i)]\n",
    "        raw_MTA_data_tmp_copy[\"Desc\"] = raw_MTA_data_tmp_copy[\"DESC\" + str(i)]\n",
    "        raw_MTA_data_tmp_x8 = pd.concat([raw_MTA_data_tmp_x8,raw_MTA_data_tmp_copy])\n",
    "\n",
    "    return raw_MTA_data_tmp_x8[raw_MTA_data_tmp_x8.columns[-6:]].copy(deep=True)\n",
    "\n",
    "raw_MTA_data_tmp = expandRows(raw_MTA_data_tmp)\n",
    "\n",
    "print(raw_MTA_data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate net entries and exits for each turnstile-date and each turnstile\n",
    "\n",
    "def getNetEntriesExits(MTA_turnstiles):\n",
    "    #sort & make ID the index...\n",
    "    MTA_turnstiles[\"ID\"] = MTA_turnstiles[\"Unit\"] + \" \" + MTA_turnstiles[\"Datetime\"] \n",
    "    MTA_turnstiles_sorted = MTA_turnstiles.sort_values(by=[\"ID\"])\n",
    "    #print(len(MTA_turnstiles_sorted))\n",
    "    MTA_turnstiles_sorted = MTA_turnstiles_sorted.drop_duplicates(subset=[\"ID\"])\n",
    "    #print(len(MTA_turnstiles_sorted))\n",
    "\n",
    "    #calculate net entries / exits for the day\n",
    "    MTA_turnstiles_grouped = MTA_turnstiles_sorted.groupby([\"Unit\"])\n",
    "    MTA_turnstiles_sorted[\"Cumulative entries\"] = pd.to_numeric(MTA_turnstiles_sorted[\"Cumulative entries\"], errors=\"coerce\")\n",
    "    MTA_turnstiles_sorted[\"Cumulative exits\"] = pd.to_numeric(MTA_turnstiles_sorted[\"Cumulative exits\"], errors=\"coerce\")\n",
    "    MTA_turnstiles_sorted[\"Net entries\"] = MTA_turnstiles_grouped[\"Cumulative entries\"].transform(pd.Series.diff)\n",
    "    MTA_turnstiles_sorted[\"Net exits\"] = MTA_turnstiles_grouped[\"Cumulative exits\"].transform(pd.Series.diff)\n",
    "\n",
    "    #data cleaning (deal with edge cases like negatives, NaN, etc. )\n",
    "    # (MTA_turnstiles_sorted[\"Net entries\"].astype(\"float64\").describe(percentiles=[.1,.25,.5,.75,.9]))\n",
    "    # print(MTA_turnstiles_sorted[\"Net exits\"].describe())\n",
    "    # print('Number of negative entries: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net entries'] < 0])) #caused by system resets\n",
    "    # print('Number of negative exits: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net exits'] < 0])) #caused by system resets\n",
    "    # print('Number of NaN entries: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net entries'].isnull()])) #caused by net zero difference\n",
    "    # print('Number of NaN exits: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net exits'].isnull()])) #caused by net zero difference\n",
    "\n",
    "    #set outliers to zero\n",
    "    MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted[\"Net entries\"] < 0] = 0\n",
    "    MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted[\"Net exits\"] < 0] = 0\n",
    "    MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted[\"Net entries\"] > 10000] = 0 #assumption: max error threshold\n",
    "    MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted[\"Net exits\"] > 10000] = 0 #assumption: max error threshold\n",
    "    MTA_turnstiles_sorted[\"Net entries\"] = MTA_turnstiles_sorted[\"Net entries\"].fillna(0)\n",
    "    MTA_turnstiles_sorted[\"Net exits\"] = MTA_turnstiles_sorted[\"Net exits\"].fillna(0)\n",
    "\n",
    "    # print('Number of negative entries: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net entries'] < 0])) #caused by system resets\n",
    "    # print('Number of negative exits: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net exits'] < 0])) #caused by system resets\n",
    "    # print('Number of NaN entries: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net entries'].isnull()])) #caused by net zero difference\n",
    "    # print('Number of NaN exits: %d' %len(MTA_turnstiles_sorted.loc[MTA_turnstiles_sorted['Net exits'].isnull()])) #caused by net zero difference\n",
    "\n",
    "    MTA_turnstiles_sorted[\"Date\"] = pd.to_datetime(MTA_turnstiles_sorted[\"Datetime\"], errors=\"coerce\", yearfirst = True).dt.strftime('%y-%m-%d')\n",
    "    MTA_turnstiles_by_day = MTA_turnstiles_sorted.groupby(by=[\"Unit\", \"Date\"]).agg({\"Net entries\": [\"sum\"]})\n",
    "    MTA_turnstiles_by_day = MTA_turnstiles_by_day.reset_index()\n",
    "    MTA_turnstiles_by_day.columns = MTA_turnstiles_by_day.columns.get_level_values(0)\n",
    "    return MTA_turnstiles_sorted, MTA_turnstiles_by_day\n",
    "\n",
    "MTA_turnstiles = raw_MTA_data_tmp.copy(deep=True)\n",
    "MTA_turnstiles, MTA_turnstiles_by_day  = getNetEntriesExits(MTA_turnstiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2: What is the total number of entries & exits across the subway system for February 1, 2013?\n",
      "5818588.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 2: What is the total number of entries & exits across the subway system for February 1, 2013?\")\n",
    "print(MTA_turnstiles_by_day.loc[MTA_turnstiles_by_day[\"Date\"] == \"13-02-01\"].sum()[\"Net entries\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3: Letâ€™s define the busy-ness as sum of entry & exit count. What station was the busiest on February 1, 2013? What turnstile was the busiest on that date?\n",
      "The most busy station is 34 ST-PENN STA and it had 348286 entries/exits\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 3: Letâ€™s define the busy-ness as sum of entry & exit count. What station was the busiest on February 1, 2013? What turnstile was the busiest on that date?\")\n",
    "\n",
    "def getBusynessByStation(MTA_turnstiles):\n",
    "    MTA_turnstiles[\"Busy-ness\"] = MTA_turnstiles[\"Net entries\"] + MTA_turnstiles[\"Net exits\"] \n",
    "    MTA_stations_by_day = MTA_turnstiles.groupby(by=[\"Station\", \"Date\"]).agg({\"Busy-ness\": [\"sum\"]})\n",
    "    MTA_stations_by_day = MTA_stations_by_day.reset_index()\n",
    "    MTA_stations_by_day.columns = MTA_stations_by_day.columns.get_level_values(0)\n",
    "    return MTA_stations_by_day\n",
    "\n",
    "MTA_stations_by_day = getBusynessByStation(MTA_turnstiles)\n",
    "MTA_stations_by_dayFeb1st = MTA_stations_by_day.loc[MTA_stations_by_day[\"Date\"] == \"13-02-01\"].sort_values(by=\"Busy-ness\")\n",
    "busiestStationName = MTA_stations_by_dayFeb1st.iloc[-1][\"Station\"]\n",
    "busiestStationTransactions = int(MTA_stations_by_dayFeb1st.iloc[-1][\"Busy-ness\"])\n",
    "\n",
    "print(\"The most busy station is {0} and it had {1} entries/exits\".format(busiestStationName, busiestStationTransactions)) #likely  times square, grand central,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4: What stations have seen the most usage growth/decline in 2013?\n"
     ]
    }
   ],
   "source": [
    "# Build this data frame for 2012 and 2013.\n",
    "# rows = calendar days for that year (365)\n",
    "# columns = busyness for each station, \"day of week\" (~300)\n",
    "\n",
    "#1. To create each dataframe, write a method which iterates over all weeks of that year. \n",
    "#   1a. For each week, return a dataframe with rows = days, columns = busyness for each station\n",
    "#   1b. append to the original dataframe\n",
    "#2. groupby day to sum up total busyness (~300 x 365 rows --> ~300x 1 rows)\n",
    "#3. Create a row with summation of all dates\n",
    "#4. Transpose 2012 and 2013 stations x day. merge into one dataset\n",
    "#5. Calculate usage growth / decline by station\n",
    "\n",
    "def getMTAStationsByDay(dateStr):\n",
    "    #turnstile x (8 hrs of data)\n",
    "    raw_data = read_MTA_csv(\"~/Projects/NYC_MTA_DATA_ANALYSIS/data/source-csv/\" + dateStr + \".csv\") #reads data and adds columns\n",
    "    raw_data = addStationName(\"../data/Remote-Booth-Station.xls\", raw_data) #adds station name\n",
    "    \n",
    "    #turnstile x (1 hrs of data)\n",
    "    raw_data = expandRows(raw_data)\n",
    "    \n",
    "    #turnstile x (1 day of data)\n",
    "    MTA_turnstiles = raw_data.copy(deep=True)\n",
    "    MTA_turnstiles, MTA_turnstiles_by_day = getNetEntriesExits(MTA_turnstiles)\n",
    "    \n",
    "    #station x (1 day of data)...7 days of data\n",
    "    MTA_stations_by_day = getBusynessByStation(MTA_turnstiles)\n",
    "    return MTA_stations_by_day\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_2013 = pd.date_range(start='1/2/2013', freq=\"W-SAT\", periods = 51)\n",
    "station_date_busyness2013 = pd.DataFrame()\n",
    "for date in dates_2013.strftime(\"%y%m%d\"):\n",
    "    station_date_busyness2013 = pd.concat([station_date_busyness2013, getMTAStationsByDay(date)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/twosigma/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "dates_2012 = pd.date_range(start='1/2/2012', freq=\"W-SAT\", periods = 51) #NOTE: manually had to change 20120714.csv since there are junk rows in the beginning 10 rows \n",
    "station_date_busyness2012 = pd.DataFrame()\n",
    "for date in dates_2012.strftime(\"%y%m%d\"):\n",
    "    station_date_busyness2012 = pd.concat([station_date_busyness2012, getMTAStationsByDay(date)])\n",
    "    \n",
    "# station_date_busyness2012 = readMTA_CSV(station_date_busyness2013,\"120714\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4: What stations have seen the most usage growth/decline in 2013?\n",
      "                 Busy-ness_2012  Busy-ness_2013  \\\n",
      "Station                                           \n",
      "JOURNAL SQUARE       15758024.0      11657819.0   \n",
      "WHITEHALL ST         15841461.0      11979171.0   \n",
      "NEWARK HW BMEBE      15601192.0      13299964.0   \n",
      "THIRTY ST            18561196.0      17082756.0   \n",
      "CASTLE HILL AVE       3717151.0       2826447.0   \n",
      "...                         ...             ...   \n",
      "ROOSEVELT AVE        27652048.0      29989408.0   \n",
      "FULTON ST            34859135.0      37476450.0   \n",
      "ATLANTIC AVE         22794118.0      25693646.0   \n",
      "34 ST-PENN STA       95204739.0      98249708.0   \n",
      "42 ST-GRD CNTRL      81991428.0      85190086.0   \n",
      "\n",
      "                 2013 delta (vs. 2012) - # change  \\\n",
      "Station                                             \n",
      "JOURNAL SQUARE                         -4100205.0   \n",
      "WHITEHALL ST                           -3862290.0   \n",
      "NEWARK HW BMEBE                        -2301228.0   \n",
      "THIRTY ST                              -1478440.0   \n",
      "CASTLE HILL AVE                         -890704.0   \n",
      "...                                           ...   \n",
      "ROOSEVELT AVE                           2337360.0   \n",
      "FULTON ST                               2617315.0   \n",
      "ATLANTIC AVE                            2899528.0   \n",
      "34 ST-PENN STA                          3044969.0   \n",
      "42 ST-GRD CNTRL                         3198658.0   \n",
      "\n",
      "                 2013 delta (vs. 2012) - % change   \n",
      "Station                                             \n",
      "JOURNAL SQUARE                           -0.260198  \n",
      "WHITEHALL ST                             -0.243809  \n",
      "NEWARK HW BMEBE                          -0.147503  \n",
      "THIRTY ST                                -0.079652  \n",
      "CASTLE HILL AVE                          -0.239620  \n",
      "...                                            ...  \n",
      "ROOSEVELT AVE                             0.084528  \n",
      "FULTON ST                                 0.075083  \n",
      "ATLANTIC AVE                              0.127205  \n",
      "34 ST-PENN STA                            0.031983  \n",
      "42 ST-GRD CNTRL                           0.039012  \n",
      "\n",
      "[370 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 4: What stations have seen the most usage growth/decline in 2013?\") \n",
    "print(\"Top 5 stations and bottom by stations by 'busy-ness' growth / decline in 2013 (vs. 2012)\") \n",
    "\n",
    "station_busyness2013 = station_date_busyness2013[[\"Station\", \"Busy-ness\"]].groupby(by=\"Station\").agg([\"sum\"])\n",
    "station_busyness2012 = station_date_busyness2012[[\"Station\", \"Busy-ness\"]].groupby(by=\"Station\").agg([\"sum\"])\n",
    "\n",
    "station_busyness2013.columns = station_busyness2013.columns.get_level_values(0)\n",
    "station_busyness2012.columns = station_busyness2012.columns.get_level_values(0)\n",
    "\n",
    "station_busyness = station_busyness2012.merge(station_busyness2013,on=\"Station\",how=\"inner\",suffixes=[\"_2012\", \"_2013\"])\n",
    "station_busyness[\"2013 delta (vs. 2012) - # change\"] = station_busyness[\"Busy-ness_2013\"] - station_busyness[\"Busy-ness_2012\"] \n",
    "station_busyness[\"2013 delta (vs. 2012) - % change \"] = (station_busyness[\"Busy-ness_2013\"] - station_busyness[\"Busy-ness_2012\"]) /  station_busyness[\"Busy-ness_2012\"]\n",
    "\n",
    "print(station_busyness.sort_values(by=\"2013 delta (vs. 2012) - # change\"))\n",
    "print()\n",
    "#print(station_busyness.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 5: What dates are the least busy? Could you identify days on which stations were not operating at full capacity or closed entirely?\n",
      "5a) dates which are least busy:\n",
      "          Busy-ness\n",
      "Date               \n",
      "70-01-01        0.0\n",
      "13-02-09  3819532.0\n",
      "13-11-28  4281751.0\n",
      "13-02-03  4434525.0\n",
      "13-01-27  4513943.0\n",
      "13-01-06  4545989.0\n",
      "13-01-13  4551911.0\n",
      "13-02-10  4641424.0\n",
      "13-02-24  4646116.0\n",
      "13-01-01  4721158.0\n",
      "           Busy-ness\n",
      "Date                \n",
      "13-09-25  10983346.0\n",
      "13-12-11  10989162.0\n",
      "13-12-05  10997114.0\n",
      "13-11-08  11004719.0\n",
      "13-12-04  11007766.0\n",
      "13-12-13  11010036.0\n",
      "13-12-12  11027993.0\n",
      "13-10-25  11028587.0\n",
      "13-10-09  11030564.0\n",
      "13-10-24  11092014.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 5: What dates are the least busy? Could you identify days on which stations were not operating at full capacity or closed entirely?\")\n",
    "#Goal 1: Find dates which are least busy\"\n",
    "#1. Using 2013 dataset from above, group by date.\n",
    "print(\"5a) dates which are least busy:\")\n",
    "print(\"Typically the days in Q1 are the least busy, almost half as busy as the most-busy days (occuring in the holiday season around December)\")\n",
    "\n",
    "date_busyness2013 = station_date_busyness2013[[\"Date\", \"Busy-ness\"]].groupby(by=\"Date\").agg([\"sum\"])\n",
    "date_busyness2013.columns = date_busyness2013.columns.get_level_values(0)\n",
    "print(date_busyness2013.sort_values(by=\"Busy-ness\").head(10))\n",
    "#print(date_busyness2013.sort_values(by=\"Busy-ness\").tail(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5b) dates on which stations aren't at full capacity or are closed entirely:\n"
     ]
    }
   ],
   "source": [
    "#Goal 2: Find days on which stations aren't at fully capacity or closed entirely\n",
    "# 1. Use 2013 dataset from above. classify each day as a weekday or weekend.\n",
    "# 2. Create two tables, representing the maximum capacity for that year. one for weekends, one for weekdays\n",
    "#   2a. for each table group by station and filter by weekend/weekday (stations x max(busyness))\n",
    "# 3. Then, for each station, iterate through all weekdays and weekends of 2013. return all dates where there is < 10% capacity or 0% capacity.\n",
    "\n",
    "\n",
    "station_date_busyness2013[\"Date2\"] = pd.to_datetime(station_date_busyness2013[\"Date\"], yearfirst=True)\n",
    "station_date_busyness2013[\"Day of week\"] = station_date_busyness2013[\"Date2\"].apply(lambda x: x.dayofweek)\n",
    "station_date_busyness2013[\"Weekend or weekday?\"] = np.where(station_date_busyness2013[\"Day of week\"] < 5, \"Weekday\", \"Weekend\")\n",
    "\n",
    "#get weekends\n",
    "station_busyness2013_weekends = station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekend\",[\"Station\", \"Busy-ness\", \"Weekend or weekday?\"]]\n",
    "station_busyness2013_weekends = station_busyness2013_weekends.groupby(\"Station\").agg([\"max\"])\n",
    "station_busyness2013_weekends.columns = station_busyness2013_weekends.columns.get_level_values(0)\n",
    "#print(station_busyness2013_weekends)\n",
    "\n",
    "#get weekdays\n",
    "station_busyness2013_weekdays = station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekday\",[\"Station\", \"Busy-ness\", \"Weekend or weekday?\"]]\n",
    "station_busyness2013_weekdays = station_busyness2013_weekdays.groupby(\"Station\").agg([\"max\"])\n",
    "station_busyness2013_weekdays.columns = station_busyness2013_weekdays.columns.get_level_values(0)\n",
    "#print(station_busyness2013_weekdays)\n",
    "\n",
    "\n",
    "station_busyness2013_weekends = station_busyness2013_weekends.to_dict()[\"Busy-ness\"]\n",
    "station_busyness2013_weekdays = station_busyness2013_weekdays.to_dict()[\"Busy-ness\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2013, there were 246 closures of stations, where there was zero traffic registered\n",
      "              Station      Date  % capacity used\n",
      "967       BEACH 90 ST  12-12-29              0.0\n",
      "968       BEACH 90 ST  12-12-30              0.0\n",
      "969       BEACH 90 ST  12-12-31              0.0\n",
      "971       BEACH 90 ST  13-01-02              0.0\n",
      "973       BEACH 90 ST  13-01-04              0.0\n",
      "...               ...       ...              ...\n",
      "1555  FRESH POND ROAD  13-12-07              0.0\n",
      "1856    KNICKERBOCKER  13-12-07              0.0\n",
      "2303       SENECA AVE  13-12-08              0.0\n",
      "2444  VAN ALSTON-21ST  13-12-14              0.0\n",
      "2445  VAN ALSTON-21ST  13-12-15              0.0\n",
      "\n",
      "[246 rows x 3 columns]\n",
      "------------------------------------------------------------\n",
      "In 2013, there were 4466 occurences where stations had lower capacity (between 0% and 75% capacity)\n",
      "              Station      Date  % capacity used\n",
      "66    116 ST-COLUMBIA  12-12-31         0.245681\n",
      "67    116 ST-COLUMBIA  13-01-01         0.212808\n",
      "109    138 ST-GR CONC  13-01-01         0.210172\n",
      "156    149 ST-GR CONC  12-12-31         0.285800\n",
      "157    149 ST-GR CONC  13-01-01         0.172162\n",
      "...               ...       ...              ...\n",
      "2482  W 8 ST-AQUARIUM  13-12-17         0.213975\n",
      "2483  W 8 ST-AQUARIUM  13-12-18         0.230740\n",
      "2484  W 8 ST-AQUARIUM  13-12-19         0.239884\n",
      "2485  W 8 ST-AQUARIUM  13-12-20         0.224187\n",
      "2514     WHITEHALL ST  13-12-14         0.294166\n",
      "\n",
      "[4466 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"5b) dates on which stations aren't at full capacity or are closed entirely:\")\n",
    "\n",
    "station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekend\",\"Max capacity for station\"] = station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekend\",\"Station\"].map(station_busyness2013_weekends)\n",
    "station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekday\",\"Max capacity for station\"] = station_date_busyness2013.loc[station_date_busyness2013[\"Weekend or weekday?\"] == \"Weekday\",\"Station\"].map(station_busyness2013_weekdays)\n",
    "station_date_busyness2013[\"Busy-ness\"] = station_date_busyness2013[\"Busy-ness\"].astype(\"float\")\n",
    "station_date_busyness2013[\"Max capacity for station\"] = station_date_busyness2013[\"Max capacity for station\"].astype(\"float\")\n",
    "station_date_busyness2013[\"% capacity used\"] = (station_date_busyness2013[\"Busy-ness\"] / station_date_busyness2013[\"Max capacity for station\"])\n",
    "\n",
    "print(\"In 2013, there were {0} closures of stations, where there was zero traffic registered\".format(station_date_busyness2013.loc[station_date_busyness2013[\"% capacity used\"] == 0.0].shape[0]))\n",
    "print(station_date_busyness2013.loc[station_date_busyness2013[\"% capacity used\"] == 0.0,[\"Station\", \"Date\", \"% capacity used\"]])\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"In 2013, there were {0} occurences where stations had lower capacity (between 0% and 75% capacity)\".format(station_date_busyness2013.loc[(station_date_busyness2013[\"% capacity used\"] > 0.0) & (station_date_busyness2013[\"% capacity used\"] < .30)].shape[0]))\n",
    "print(station_date_busyness2013.loc[(station_date_busyness2013[\"% capacity used\"] > 0.0) & (station_date_busyness2013[\"% capacity used\"] < .30),[\"Station\", \"Date\", \"% capacity used\"]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e92a65bea0caed0c1b2e444ffa4813b1725cbc7086e0d7c70a637107a7975c88"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('twosigma': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}